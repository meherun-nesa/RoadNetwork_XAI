{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFc1Ic0iBIyL023XbapJRr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHJ3gKOOX95f","executionInfo":{"status":"ok","timestamp":1652517988861,"user_tz":-540,"elapsed":25250,"user":{"displayName":"meherun nesa","userId":"11402551051434719143"}},"outputId":"dae08aeb-029e-4ec8-ee76-4d342c3545cd"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86YOp_4uX-pW","executionInfo":{"status":"ok","timestamp":1652517995394,"user_tz":-540,"elapsed":383,"user":{"displayName":"meherun nesa","userId":"11402551051434719143"}},"outputId":"b14b98cd-39a0-4207-ac84-82660d76dab0"},"source":["cd /content/gdrive/MyDrive/XAI/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/XAI\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TM8Dd7ZBSQY","executionInfo":{"status":"ok","timestamp":1652518017957,"user_tz":-540,"elapsed":17292,"user":{"displayName":"meherun nesa","userId":"11402551051434719143"}},"outputId":"df6af4ad-0416-4587-a5ab-27155c4060a0"},"source":["#from random import shuffle\n","!pip install folium\n","import folium\n","import pickle\n","import math\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import numpy as np\n","import keras\n","import random as rn\n","import tensorflow as tf\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.nn.parameter import Parameter\n","from torch.nn.modules.module import Module\n","import torch.nn.functional as F\n","#from torch_geometric.nn.dense import DenseGCNConv\n","from keras.layers import Activation, Dense\n","from numpy import array as narray\n","from numpy import inf, median\n","from tensorflow.keras.optimizers import SGD,Adagrad, Adam, RMSprop\n","\n","import easydict\n","import os\n","#import cupy #런타임 gpu 사용시 \n","import argparse\n","import dill\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from math import atan\n","#런타임gpu사용시 \n","#from cupy import zeros, full, where, identity, divide, add, array, ndarray, asarray, asnumpy, stack, vstack, subtract, newaxis, multiply, ones, less, minimum, copy, concatenate, exp, repeat, tile, matmul, isnan, sqrt, log, NaN#, nanmean\n","\n","import time\n","from queue import Queue\n","from sklearn.metrics import mean_squared_error\n","#geopandas\n","!pip install geopandas\n","import geopandas as gpd\n","import requests\n","from bs4 import BeautifulSoup\n","from sklearn.preprocessing import MinMaxScaler\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: folium in /usr/local/lib/python3.7/dist-packages (0.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from folium) (2.23.0)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from folium) (0.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from folium) (1.21.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from folium) (2.11.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from folium) (1.15.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->folium) (2.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->folium) (3.0.4)\n","Collecting geopandas\n","  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 21.2 MB/s \n","\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.1.post1)\n","Collecting fiona>=1.8\n","  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n","\u001b[K     |████████████████████████████████| 16.7 MB 51.2 MB/s \n","\u001b[?25hCollecting pyproj>=2.2.0\n","  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 24.5 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Collecting click-plugins>=1.0\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.1)\n","Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n"]}]},{"cell_type":"code","metadata":{"id":"X-5mmhdOYDl4"},"source":["#1차 전처리 \n","def InfoMatrix(g) :\n","    adj = np.zeros((g.shape[0], g.shape[0])) # adj 초기화\n","    for i in range(g.shape[0]) :\n","        idx = g[g['dst'] == g.at[i, 'src']].index.tolist() #연결이 되어 있으면 idx로 인덱스 정보 추출\n","        idx.extend(g[g['src'] == g.at[i, 'dst']].index.tolist())\n","        #print('IDS shape check : ',np.shape(idx))\n","        adj[i, idx] = 1 # 인접행렬을 생성\n","    return adj\n","    \n","def BaseInfo() : # 데이터 로드\n","    speed = pickle.load(open('2018_5pclean_tMatrix.pkl', 'rb')) # 속도 데이터 로드\n","    g = pickle.load(open('Graph_info.pkl', 'rb')).sort_values(by=['str_id']).reset_index(drop = True) # 인접관계 정보 데이터 로드\n"," \n","    # End Point 변환\n","    g.loc[g[g['dst'].isin(['힐튼'])].index,'dst'] = '도동삼거리'\n","    g.loc[g[g['dst'].isin(['힐튼'])].index,'dist'] = 322\n","    \n","    speed.drop(['3201500100'], axis = 1, inplace = True) # 기후 정보가 없는 링크 드랍\n","    g = g[g['str_id'] != '3201500100'].sort_values(by=['str_id']).reset_index(drop = True)\n","    g = g.sort_values(by=['str_id']).reset_index(drop = True)\n","\n","    linklist = g['str_id'].values # 링크 ID 추출\n","    dist = g['dist'].astype(int).values # 거리 데이터 추출\n","    \n","    #adj = InfoMatrix(g) # 인접행렬 adj랑, cost행렬 추출\n","    dist = np.asarray(dist)\n","    #speed = np.asarray(speed.values)\n","    speed = np.asarray(speed.values).astype('float32')\n","   \n","    hopadj = pickle.load(open('tg1_hopadj.picle', 'rb'))\n","    lnewspeed = pickle.load(open('lnewspeed.picle', 'rb')) #local 노드별  scaled 된 속도 데이터 로드\n","    gnewspeed = pickle.load(open('gnewspeed.picle', 'rb')) #global하게  scaled 된 속도 데이터 로드\n","    return hopadj, g, speed, lnewspeed, gnewspeed\n","\n","\n","#hop count 계산 -> BFS알고리즘사용\n","def bfs(adj, start_node):\n","  x= len(adj)\n","  visit=[0]*x\n","  ch = [0]*x\n","  q = Queue()\n","  for s in np.where(adj[start_node]==1)[0]:\n","    q.put(s)\n","    visit[s]=1\n","    ch[s]=1\n","  while q.qsize()>0 :\n","    node = q.get()\n","    for nextN in np.where(adj[node]==1)[0]:\n","      if nextN != start_node and ch[nextN]==0:\n","        ch[nextN]=1\n","        q.put(nextN)\n","        visit[nextN]=visit[node]+1          \n","  return visit\n","\n","def make_hopadj(adj): #hop count matrix 생성\n","  tg1_hopadj=[]\n","  for i in range(len(adj)):\n","    tg1_hopadj.append(bfs(adj, i))\n","\n","  with open('tg1_hopadj.picle', 'wb') as f:\n","    pickle.dump(tg1_hopadj, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAU_qoXjFNOZ"},"source":["'''\n","* fn1 : make_features(hopadj,speed, obj, tg)\n","dnn input을 만드는 함수로 obj가 test 인지 train인지에 맞추어서 input 생성하는 함수\n","input :\n","  hopadj = hop count 정보 \n","  speed = feature 만들기 위한 데이터 \n","  obj = list of 'test' OR 'train' index\n","  tg = target node idx\n","\n","output :2차원( #train or test , #hop5이내 + 3)\n","obj의 hours에서 tg의 features\n","\n","* fn2 : make_output(speed, obj, tg)\n","지도 학습이기에 ouput값이 필요, dnn의 ouput을 생성하는 함수\n","\n","* fn3 : make_features_simulation(hopadj,speed, t, tg)\n","시뮬레이션 시 필요한 input 생성하는 함수\n","'''\n","def make_features(hopadj,speed, obj, tg): \n","  \n","  #print(np.shape(hopadj))#(4670, 4670)\n","  check = True\n","  input_tg=[]\n","  for t in (obj): # (실험용) 노드에 대해서\n","    features=[] #(#hop5노드들 + 시각 + 요일,) 으로 features 표현 : \n","    features.append(speed[t][tg].item()) # 해당 노드의 t시간대 속도\n","    for cnt in range(1,6): #hop count 1~5 까지\n","      hop_idx =  np.where(np.array(hopadj[tg])==cnt)[0]      \n","      #print(hop_idx)\n","      features.extend(speed[t][hop_idx])\n","    features.append( ( t%24 +1 )/24) #시각\n","    features.append( ( (t//24)%7 + 1 ) /7 ) #요일\n","    input_tg.append(features)\n","  \n","  if check:\n","    check=False\n","    #print('input_tg shape : (pred:  (#train or test , hop5이내 + 3)) vs ',np.shape(input_tg))# 2차원 (#train or test , hop5이내 갯수 + 3(자기자신속도,시각, 요일))\n","\n","  return input_tg\n","\n","\n","def make_output(speed, obj, tg): #t시간대의 output --> t+1의 값 \n","  output_tg = []  \n","  for t in (obj):\n","    output_tg.append(speed[t+1][tg]) # 특정 시간 t에서의 전체 노드의 speed\n","  #print('output_tg shape : (pred:  (#train or test ) vs', np.shape(output_tg )) #(train or test,)\n","  return output_tg  \n","\n","def make_features_simulation(hopadj,speed, t, tg): \n","  \n","  feature=[] #(#hop5노드들 + 시각 + 요일,) 으로 features 표현 : \n","  feature.append(speed[t][tg].item()) # 해당 노드의 t시간대 속도\n"," \n","  for cnt in range(1,6): #hop count 1~5 까지\n","    hop_idx =  np.where(np.array(hopadj[tg])==cnt)[0]      \n","    feature.extend(speed[t][hop_idx])\n","  feature.append( ( t%24 +1 )/24) #시각\n","  feature.append( ( (t//24)%7 + 1 ) /7 ) #요일\n","  \n","  return feature    "],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def RMSE(y_test, y_predict): #판단 지표\n","    return np.sqrt(mean_squared_error(y_test, y_predict))\n","\n","def MAPE(y_test, y_predict): #판단 지표\n","    return np.mean(np.abs((y_test-y_predict)/y_test))*100  "],"metadata":{"id":"BwCy357gbXoB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__=='__main__':    \n","  #Feature scaling  (x-mean)/(std) -> newspeed.picle로 저장해둠  \n"," \n","  #loading data\n","  hopadj, graphinfo, speed, lnewspeed, gnewspeed = BaseInfo() \n","  \n","  #np.where조건식 2개 거는 방법\n","  ##idx0 =  np.where( (np.array(hopadj[0]) >=1) & (np.array(hopadj[0])<=5) )[0] \n","  #adj 정규화  https://math.stackexchange.com/questions/3295135/how-is-the-adjacency-matrix-of-a-directed-graph-normalized\n","  \n","  ##########################################################################################\n","  #Step0) test train split\n","  ################################\n","  days = [31,28,31,30,31,30,31,31,30,31,30,31] #days of a year e.g) Jan: 31days, Feb: 28days, Mar: 31days ..\n","  for i in range(12):\n","    if i==0:\n","      pass\n","    else:\n","      days[i]+=days[i-1]\n","\n","  month_test=[1,4,7,10]#Test: [2 Feb,5 May,8 Aug,11 Nov]\n","  hour_train = []\n","  hour_test = []\n","\n","  #Split train & test data\n","  for i in range(12):\n","    if i == 0:\n","      tmp = range(0, days[i]*24)\n","    else:\n","      tmp = range(days[i-1] * 24, days[i]*24)\n","    if i in month_test:\n","      hour_test.extend(tmp)\n","    else:\n","      hour_train.extend(tmp)\n","  hour_train.pop() #NO next(t+1) data for a last day, so pop()\n","  print('hour_train len: ',len(hour_train))\n","  print('hour_test len : ', len(hour_test))\n","\n","  ##########################################################################################\n","  #Step1) Set Base road        # e.g)'여의나루로','역삼로','방배로' road_name\n","  ####################################################################\n","  road_name = '여의나루로' # ****Set road namae****\n","\n","  ginfo = pd.DataFrame(graphinfo)\n","  tg1 = ginfo[ginfo['road'].str.contains(road_name)]\n","  tg1idx = tg1.index.tolist()  \n","  print('tg1 {} idx : {}'.format(road_name, tg1idx)) #여의나루로 tg1idx: [4629, 4630, 4631, 4632, 4640, 4641] \n","  print(tg1) #확인용                                  # --> 6 base roads in 'Yeoyinaru-Ro' -> each road is called 'tg' in code\n","\n","  #globally하게 scaled된 speed data 사용!\n","  newspeed = gnewspeed\n","  scaled = 'G'\n","  ####################################\n","  tg1idx = tg1idx[4:5]\n","\n","  for tg in tg1idx:\n","\n","     #generate model for each base node\n","    print('** Current : {} out of {}'.format(tg,tg1idx)) \n","    input_train = np.asarray(make_features(hopadj,newspeed, hour_train,tg)).astype('float32') \n","    output_train = np.asarray(make_output(newspeed, hour_train, tg)).astype('float32')\n","\n","    input_test = np.asarray(make_features(hopadj, newspeed, hour_test,tg)).astype('float32')\n","    output_test = np.asarray(make_output(newspeed, hour_test, tg)).astype('float32')\n","\n","  input_train_df = pd.DataFrame(input_train, columns = ['base_id','3190','3219','3223','3244','4629',\n","           '2978','2983','2984','3156','3158','3187','3191','3199','3218','3222','3245','3254','4630','4631',\n","           '398','2081','2083','2976','2979','2982','2985','3126','3128','3134','3136','3153','3157','3159','3167','3175','3186','3198','3230','3255','3258','4632','4641',\n","           '393','395','397','445','470','2082','2084','2085','2087','2145','2974','2977','3114','3115','3116','3117','3123','3127','3129','3135','3137','3152','3166','3174','3179','3231','3259','3268','3352',\n","           '176','389','392','394','446','455','456','469','477','2086','2088','2091','2093','2146','2147','2148','2152','2158','2164','2970','2975','3122','3178','3185','3211','3261','3269','3278','3294','3295','3344','3351','3353','3354','3355',\n","           'clock_time','day']) \n","\n","  output_train_df = pd.DataFrame(output_train, columns = ['(t+1)speed'])\n","\n","  input_test_df = pd.DataFrame(input_test, columns = ['base_id','3190','3219','3223','3244','4629',\n","           '2978','2983','2984','3156','3158','3187','3191','3199','3218','3222','3245','3254','4630','4631',\n","           '398','2081','2083','2976','2979','2982','2985','3126','3128','3134','3136','3153','3157','3159','3167','3175','3186','3198','3230','3255','3258','4632','4641',\n","           '393','395','397','445','470','2082','2084','2085','2087','2145','2974','2977','3114','3115','3116','3117','3123','3127','3129','3135','3137','3152','3166','3174','3179','3231','3259','3268','3352',\n","           '176','389','392','394','446','455','456','469','477','2086','2088','2091','2093','2146','2147','2148','2152','2158','2164','2970','2975','3122','3178','3185','3211','3261','3269','3278','3294','3295','3344','3351','3353','3354','3355',\n","           'clock_time','day']) \n","\n","  output_test_df = pd.DataFrame(output_test, columns = ['(t+1)speed']) \n","\n","  from sklearn.linear_model import Lasso\n","  model = Lasso(alpha=1.0)\n","  model.fit(input_train_df,output_train_df)\n","        \n","  ii = model.predict(input_test_df)\n","  print(np.shape(ii))\n","     \n","  ii = ii*130+0.74\n","  oo = output_test*130+0.74\n","      \n","  print('Slope: %.2f'% model.coef_[0])\n","  print('Intercept: %.2f'% model.intercept_)\n","  print('실제 속도로 본 RMSE :  ',RMSE(oo, ii)) # 실제, predict \n","\n","  from sklearn.metrics import mean_absolute_error\n","  print(\"MAE:\",mean_absolute_error(oo,ii))\n","\n","  print(\"MAPE:\",MAPE(oo,ii))\n"," \n","  #model.save_model(\"model_sklearn_xgb.json\"+scaled+str(tg))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652518164378,"user_tz":-540,"elapsed":27220,"user":{"displayName":"meherun nesa","userId":"11402551051434719143"}},"outputId":"c67fb872-56b5-484f-c423-b32a89dbfde4","id":"zZEFqI2P2Yhd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hour_train len:  5879\n","hour_test len :  2880\n","tg1 여의나루로 idx : [4629, 4630, 4631, 4632, 4640, 4641]\n","          str_id     src     dst   road direction dist\n","4629  3201505000   문화방송앞    여의도역  여의나루로        하행  485\n","4630  3201505100    여의도역   문화방송앞  여의나루로        상행  485\n","4631  3201505200    여의도역   윤중초교앞  여의나루로        하행  398\n","4632  3201505300   윤중초교앞    여의도역  여의나루로        상행  398\n","4640  3201506200  여의중고교앞   문화방송앞  여의나루로        하행  455\n","4641  3201506300   문화방송앞  여의중고교앞  여의나루로        상행  455\n","** Current : 4640 out of [4640]\n","(2880,)\n","Slope: 0.00\n","Intercept: 0.16\n","실제 속도로 본 RMSE :   4.9031816\n","MAE: 3.6561658\n","MAPE: 16.040632128715515\n"]}]}]}